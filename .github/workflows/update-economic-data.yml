name: Update Economic Data - v8 (TE + ONS + ECB TRD + Eurostat + IMF + WorldBank)
on:
  schedule:
    - cron: '0 6 * * *'
  workflow_dispatch:

jobs:
  update-economic-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests beautifulsoup4 lxml --break-system-packages

      - name: Create data directory
        run: mkdir -p economic-data

      - name: Scrape economic data
        run: |
          python3 << 'EOFPYTHON'
          import requests
          from bs4 import BeautifulSoup
          import json, re, time
          from datetime import date, datetime

          HEADERS = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
          }
          JSON_HEADERS = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
              'Accept': 'application/json, text/csv, */*',
          }

          CURRENCIES = ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD']

          TRADING_ECONOMICS_URLS = {
              'gdp':              'https://tradingeconomics.com/country-list/gdp?continent=world',
              'gdpGrowth':        'https://tradingeconomics.com/country-list/gdp-growth-rate?continent=world',
              'inflation':        'https://tradingeconomics.com/country-list/inflation-rate?continent=world',
              'unemployment':     'https://tradingeconomics.com/country-list/unemployment-rate?continent=world',
              'debt':             'https://tradingeconomics.com/country-list/government-debt-to-gdp',
              'currentAccount':   'https://tradingeconomics.com/country-list/current-account-to-gdp?continent=world',
              'production':       'https://tradingeconomics.com/country-list/industrial-production-mom?continent=world',
              'tradeBalance':     'https://tradingeconomics.com/country-list/balance-of-trade',
              'retailSales':      'https://tradingeconomics.com/country-list/retail-sales-mom',
              'wageGrowth':       'https://tradingeconomics.com/country-list/wage-growth',
              'manufacturingPMI': 'https://tradingeconomics.com/country-list/manufacturing-pmi',
              'termsOfTrade':     'https://tradingeconomics.com/country-list/terms-of-trade',
          }

          COUNTRY_URLS = {
              'USD': 'united-states', 'EUR': 'euro-area', 'GBP': 'united-kingdom',
              'JPY': 'japan',         'CAD': 'canada',    'AUD': 'australia',
              'CHF': 'switzerland',   'NZD': 'new-zealand',
          }

          INDICATOR_PAGES = {
              'retailSales':      'retail-sales',
              'wageGrowth':       'wage-growth',
              'manufacturingPMI': 'manufacturing-pmi',
              'production':       'industrial-production',
          }

          COUNTRY_NAMES = {
              'USD': ['United States'], 'EUR': ['Euro Area'], 'GBP': ['United Kingdom'],
              'JPY': ['Japan'],         'CAD': ['Canada'],    'AUD': ['Australia'],
              'CHF': ['Switzerland'],   'NZD': ['New Zealand'],
          }

          TOT_MIN, TOT_MAX = 50.0, 200.0

          exchange_rates = {}

          # ═══════════════════════════════════════════════════════════════════
          # UTILS
          # ═══════════════════════════════════════════════════════════════════

          def fetch_fx():
              global exchange_rates
              try:
                  r = requests.get('https://api.frankfurter.app/latest?from=USD', timeout=10)
                  if r.ok:
                      exchange_rates = r.json().get('rates', {})
                      exchange_rates['USD'] = 1.0
                      return
              except:
                  pass
              exchange_rates = {'USD':1.0,'EUR':0.84,'GBP':0.73,'JPY':153.71,
                                'CAD':1.36,'AUD':1.40,'CHF':0.77,'NZD':1.65}

          def clean_num(text):
              if not text:
                  return None
              text = str(text).strip().replace(',','').replace('%','')
              m = re.search(r'(-?\d+\.?\d*)', text)
              return float(m.group(1)) if m else None

          def parse_te_date(date_text):
              if not date_text:
                  return str(date.today())
              date_text = date_text.strip()
              try:
                  m = re.search(r'([A-Za-z]{3})\s*[/\s]\s*(\d{2,4})', date_text)
                  if m:
                      yr = m.group(2)
                      if len(yr) == 2: yr = '20' + yr
                      dt = datetime.strptime(f"{m.group(1)} {yr}", '%b %Y')
                      return dt.strftime('%Y-%m-15')
                  m = re.search(r'Q(\d)[/\s](\d{4})', date_text)
                  if m:
                      q, yr = int(m.group(1)), int(m.group(2))
                      return f"{yr}-{(q-1)*3+2:02d}-15"
                  if re.match(r'^\d{4}$', date_text):
                      return f"{date_text}-06-15"
              except:
                  pass
              return str(date.today())

          def te_get(url):
              r = requests.get(url, headers=HEADERS, timeout=20)
              if r.status_code == 429:
                  print(f"  ⚠ Rate limited, waiting 30s...")
                  time.sleep(30)
                  r = requests.get(url, headers=HEADERS, timeout=20)
              r.raise_for_status()
              return r

          # ═══════════════════════════════════════════════════════════════════
          # TERMS OF TRADE — EUR source chain (4 sources)
          # ═══════════════════════════════════════════════════════════════════

          def scrape_tot_ons_gbp():
              """
              ONS API: Series CTSL (Trade in Goods Total Terms of Trade, SA)
              Dataset MRET. Returns quarterly data.
              """
              urls = [
                  "https://api.ons.gov.uk/v1/datasets/MRET/timeseries/CTSL/data",
                  "https://api.ons.gov.uk/v1/timeseries/CTSL/dataset/MRET/data",
                  "https://api.ons.gov.uk/dataset/MRET/timeseries/CTSL/data",
              ]
              for url in urls:
                  print(f"    → ONS: {url}")
                  try:
                      r = requests.get(url, headers=JSON_HEADERS, timeout=20)
                      if r.status_code == 404:
                          continue
                      r.raise_for_status()
                      data = r.json()
                      quarters = data.get('quarters', [])
                      if not quarters:
                          print(f"    ✗ ONS: no quarters in response. Keys: {list(data.keys())[:5]}")
                          continue

                      def qsort(q):
                          m = re.match(r'(\d{4})\s+Q(\d)', q.get('date',''))
                          return int(m.group(1))*10+int(m.group(2)) if m else 0

                      for q in sorted(quarters, key=qsort, reverse=True):
                          val = clean_num(q.get('value',''))
                          date_str = q.get('date','')
                          if val is not None and TOT_MIN <= val <= TOT_MAX:
                              m = re.match(r'(\d{4})\s+Q(\d)', date_str)
                              if m:
                                  yr, qn = int(m.group(1)), int(m.group(2))
                                  d = f"{yr}-{(qn-1)*3+2:02d}-15"
                              else:
                                  d = str(date.today())
                              print(f"    ✓ GBP [ONS CTSL]: {val} ({date_str})")
                              return round(val, 2), d
                  except Exception as e:
                      print(f"    ✗ ONS {url}: {e}")
              return None, None

          # ── EUR Source 1: ECB TRD dataset (unit value indices, monthly) ──────

          def fetch_tot_eur_ecb_trd():
              """
              ECB TRD dataset: unit value indices for extra-euro area trade.
              ToT = (Export UVI / Import UVI) normalised to 2020 average = 100.

              Dimension structure for TRD:
                FREQ.REF_AREA.COUNTERPART_AREA.FLOW.PRODUCT.TRANSFORMATION.UNIT_MEASURE
              Series keys tried:
                M.I8.W2.X.S1.0.VALUE  (EA20, world, exports, all products, index)
                M.I9.W2.X.S1.0.VALUE  (EA19 fallback)
              """
              ecb_base = "https://data-api.ecb.europa.eu/service/data/TRD/"

              # (export_key, import_key) pairs to try
              candidates = [
                  ("M.I8.W2.X.S1.0.VALUE", "M.I8.W2.M.S1.0.VALUE"),
                  ("M.I8.W2.X.S1.4.UVX",   "M.I8.W2.M.S1.4.UVX"),
                  ("M.I8.W2.X.TTT.4.UVX",  "M.I8.W2.M.TTT.4.UVX"),
                  ("M.I9.W2.X.S1.4.UVX",   "M.I9.W2.M.S1.4.UVX"),
              ]

              def fetch_trd_series(key):
                  url = f"{ecb_base}{key}?format=csvdata&startPeriod=2019-01&lastNObservations=36"
                  try:
                      r = requests.get(url, headers=JSON_HEADERS, timeout=20)
                      print(f"      ECB TRD {key[:30]}: HTTP {r.status_code}")
                      if not r.ok:
                          return None
                      lines = r.text.strip().splitlines()
                      if len(lines) < 2:
                          return None
                      header = [h.strip().strip('"').lower() for h in lines[0].split(',')]
                      ti = next((i for i, h in enumerate(header) if 'time_period' in h), None)
                      vi = next((i for i, h in enumerate(header) if 'obs_value' in h), None)
                      if ti is None or vi is None:
                          return None
                      results = {}
                      for line in lines[1:]:
                          cols = [c.strip().strip('"') for c in line.split(',')]
                          if len(cols) <= max(ti, vi):
                              continue
                          val = clean_num(cols[vi])
                          period = cols[ti]  # e.g. "2024-11"
                          if val and period:
                              results[period] = val
                      print(f"      → {len(results)} observations")
                      return results if results else None
                  except Exception as e:
                      print(f"      ECB TRD error ({key[:25]}): {e}")
                      return None

              print("    → ECB TRD: unit value indices extra-EA trade")
              for exp_key, imp_key in candidates:
                  exp = fetch_trd_series(exp_key)
                  imp = fetch_trd_series(imp_key)
                  if not exp or not imp:
                      continue

                  common = sorted(set(exp.keys()) & set(imp.keys()), reverse=True)
                  if not common:
                      continue

                  # 2020 average as base
                  exp_2020 = [v for p, v in exp.items() if p.startswith('2020')]
                  imp_2020 = [v for p, v in imp.items() if p.startswith('2020')]
                  if not exp_2020 or not imp_2020:
                      continue
                  base_exp = sum(exp_2020) / len(exp_2020)
                  base_imp = sum(imp_2020) / len(imp_2020)
                  if base_exp == 0 or base_imp == 0:
                      continue

                  for period in common:
                      tot = (exp[period] / imp[period]) / (base_exp / base_imp) * 100.0
                      if TOT_MIN <= tot <= TOT_MAX:
                          d = f"{period}-15" if re.match(r'^\d{4}-\d{2}$', period) else str(date.today())
                          print(f"    ✓ EUR [ECB TRD ratio]: {round(tot,2)} ({period})")
                          return round(tot, 2), d

              print("    ✗ ECB TRD: all candidates failed")
              return None, None

          # ── EUR Source 2: Eurostat ext_lt_intercc (correct ToT dataset) ──────

          def fetch_tot_eur_eurostat():
              """
              Eurostat EXT_LT_INTERCC: Terms of Trade for extra-EU/EA merchandise trade.
              This is the correct dataset — TIPSNA30 was wrong (it's a CPI dataset).
              Unit I10 = index base 2010=100. TTI = terms of trade index.
              """
              url = ("https://ec.europa.eu/eurostat/api/dissemination/statistics/1.0/data"
                     "/ext_lt_intercc?format=JSON&lang=EN&geo=EA20&lastTimePeriod=8")
              try:
                  r = requests.get(url, headers=JSON_HEADERS, timeout=25)
                  print(f"    → Eurostat ext_lt_intercc: HTTP {r.status_code}")
                  if not r.ok:
                      return None, None
                  js = r.json()

                  unit_labels = js.get('dimension', {}).get('unit', {}).get('category', {}).get('label', {})
                  unit_index  = js.get('dimension', {}).get('unit', {}).get('category', {}).get('index', {})
                  time_index  = js.get('dimension', {}).get('time', {}).get('category', {}).get('index', {})
                  values      = js.get('value', {})

                  print(f"      Units available: {list(unit_labels.values())}")

                  n_times = len(time_index)

                  # Priority: TTI > I10 > I15 > any unit with valid value in range
                  priority_units = ['TTI', 'I10', 'I15', 'TOT']

                  def try_unit(unit_code):
                      pos = unit_index.get(unit_code)
                      if pos is None:
                          return None, None
                      for time_str, time_pos in sorted(time_index.items(), key=lambda x: x[0], reverse=True):
                          idx = str(pos * n_times + time_pos)
                          val = values.get(idx)
                          if val is not None:
                              fval = float(val)
                              if TOT_MIN <= fval <= TOT_MAX:
                                  d = parse_te_date(time_str)
                                  print(f"    ✓ EUR [Eurostat {unit_code}]: {fval} ({time_str})")
                                  return round(fval, 2), d
                      return None, None

                  # Try priority units first
                  for unit_code in priority_units:
                      val, d = try_unit(unit_code)
                      if val is not None:
                          return val, d

                  # Fallback: scan all available units
                  for unit_code in unit_index.keys():
                      val, d = try_unit(unit_code)
                      if val is not None:
                          return val, d

              except Exception as e:
                  print(f"    ✗ Eurostat ext_lt_intercc: {e}")
              return None, None

          # ── EUR Source 3: IMF DataMapper API ─────────────────────────────────

          def fetch_tot_eur_imf():
              """
              IMF DataMapper API: Terms of Trade for Euro Area.
              Endpoint: /api/v1/TT/{country_code}
              EUQ = Euro Area (IMF code). TT = Terms of Trade.
              Data is annual, base 2012=100.
              """
              # Try multiple IMF country codes for Euro Area
              imf_codes = ['EUQ', 'U2', 'EUR']
              for code in imf_codes:
                  url = f"https://www.imf.org/external/datamapper/api/v1/TT/{code}"
                  try:
                      r = requests.get(url, headers=JSON_HEADERS, timeout=20)
                      print(f"    → IMF TT/{code}: HTTP {r.status_code}")
                      if not r.ok:
                          continue
                      js = r.json()
                      data = js.get('values', {}).get('TT', {}).get(code, {})
                      if not data:
                          continue
                      # data is dict of year→value, e.g. {"2020": 100.0, "2023": 97.4}
                      for yr in sorted(data.keys(), reverse=True):
                          val = data[yr]
                          if val is not None and TOT_MIN <= float(val) <= TOT_MAX:
                              print(f"    ✓ EUR [IMF TT {code}]: {val} ({yr})")
                              return round(float(val), 2), f"{yr}-06-15"
                  except Exception as e:
                      print(f"    ✗ IMF TT/{code}: {e}")
              return None, None

          # ── EUR Source 4: World Bank (last resort, ~2yr lag) ─────────────────

          def scrape_tot_wb(currency_code, timeout=30):
              """World Bank fallback: TT.PRI.MRCH.XD.WD (net barter ToT, base 2015=100)."""
              wb_map = {
                  'USD':'US','GBP':'GB','JPY':'JP','CAD':'CA',
                  'AUD':'AU','CHF':'CH','NZD':'NZ','EUR':'XC',
              }
              wb = wb_map.get(currency_code)
              if not wb:
                  return None, None
              url = (f"https://api.worldbank.org/v2/country/{wb}"
                     f"/indicator/TT.PRI.MRCH.XD.WD?format=json&mrv=5&per_page=5")
              try:
                  r = requests.get(url, headers=JSON_HEADERS, timeout=timeout)
                  r.raise_for_status()
                  data = r.json()
                  if not data or len(data) < 2 or not data[1]:
                      return None, None
                  for obs in data[1]:
                      val = obs.get('value')
                      if val is None:
                          continue
                      val = float(val)
                      if TOT_MIN <= val <= TOT_MAX:
                          yr = obs.get('date', str(date.today().year))
                          print(f"    ✓ {currency_code} [World Bank ToT {yr}]: {val}")
                          return round(val, 2), f"{yr}-06-15"
              except Exception as e:
                  print(f"    ✗ World Bank ToT {currency_code}: {e}")
              return None, None

          # ── Master ToT resolver ───────────────────────────────────────────────

          def fetch_all_tot(te_list_data, te_list_dates):
              """
              ToT resolution chain:
                1. TE list values (all currencies, reject out-of-range)
                2. GBP  → ONS API (CTSL quarterly, most current)
                3. EUR  → ECB TRD (unit value indices, monthly)
                         → Eurostat ext_lt_intercc (correct ToT dataset)
                         → IMF DataMapper (annual, 1-yr lag)
                4. Rest → World Bank (annual, ~2yr lag)
              """
              data  = {}
              dates = {}

              # Step 1: accept valid TE values
              for curr, val in te_list_data.items():
                  if TOT_MIN <= val <= TOT_MAX:
                      data[curr]  = val
                      dates[curr] = te_list_dates.get(curr, str(date.today()))
                  else:
                      print(f"  ✗ {curr} [TE list]: {val} out of range → specialist scraper")

              missing = [c for c in CURRENCIES if c not in data]
              if not missing:
                  return data, dates

              print(f"\n  → Specialist ToT for: {', '.join(missing)}")

              # Step 2: GBP via ONS
              if 'GBP' in missing:
                  val, d = scrape_tot_ons_gbp()
                  if val is not None:
                      data['GBP']  = val
                      dates['GBP'] = d
                      missing.remove('GBP')

              # Step 3: EUR — cascade through 3 specialist sources
              if 'EUR' in missing:
                  val, d = None, None

                  # 3a. ECB TRD (monthly, most current)
                  print("  → EUR ToT source 3a: ECB TRD")
                  val, d = fetch_tot_eur_ecb_trd()

                  # 3b. Eurostat ext_lt_intercc (correct dataset, quarterly)
                  if val is None:
                      print("  → EUR ToT source 3b: Eurostat ext_lt_intercc")
                      val, d = fetch_tot_eur_eurostat()

                  # 3c. IMF DataMapper (annual)
                  if val is None:
                      print("  → EUR ToT source 3c: IMF DataMapper")
                      val, d = fetch_tot_eur_imf()

                  if val is not None:
                      data['EUR']  = val
                      dates['EUR'] = d
                      missing.remove('EUR')
                  else:
                      print("  ✗ EUR: all 3 specialist sources failed")

              # Step 4: World Bank for anything still missing
              still_missing = [c for c in CURRENCIES if c not in data]
              if still_missing:
                  print(f"\n  → World Bank ToT fallback for: {', '.join(still_missing)}")
                  for curr in still_missing:
                      val, d = scrape_tot_wb(curr, timeout=30)
                      if val is not None:
                          data[curr]  = val
                          dates[curr] = d
                      time.sleep(0.5)

              final_missing = [c for c in CURRENCIES if c not in data]
              if final_missing:
                  print(f"  ⚠ No ToT available for: {', '.join(final_missing)} → null")

              return data, dates

          # ═══════════════════════════════════════════════════════════════════
          # STANDARD TE SCRAPING
          # ═══════════════════════════════════════════════════════════════════

          def scrape_country_page(country_slug, indicator_page, currency_code):
              url = f'https://tradingeconomics.com/{country_slug}/{indicator_page}'
              try:
                  r = te_get(url)
                  soup = BeautifulSoup(r.content, 'lxml')
                  for table in soup.find_all('table'):
                      headers = [h.get_text(strip=True).lower() for h in table.find_all('th')]
                      if 'last' in headers and 'reference' in headers:
                          li, ri = headers.index('last'), headers.index('reference')
                          kw = indicator_page.replace('-',' ').split()[0].lower()
                          for row in table.find_all('tr')[1:]:
                              cells = row.find_all('td')
                              if len(cells) <= max(li, ri): continue
                              if kw in cells[0].get_text(strip=True).lower():
                                  val = clean_num(cells[li].get_text(strip=True))
                                  if val is not None:
                                      d = parse_te_date(cells[ri].get_text(strip=True))
                                      print(f"    ✓ {currency_code} [related-table]: {val} ({d})")
                                      return val, d
                  for table in soup.find_all('table'):
                      headers = [h.get_text(strip=True).lower() for h in table.find_all('th')]
                      if 'actual' in headers:
                          ai = headers.index('actual')
                          di = headers.index('reference') if 'reference' in headers else None
                          rows = table.find_all('tr')[1:]
                          if rows:
                              cells = rows[0].find_all('td')
                              if len(cells) > ai:
                                  val = clean_num(cells[ai].get_text(strip=True))
                                  d = str(date.today())
                                  if di and len(cells) > di:
                                      d = parse_te_date(cells[di].get_text(strip=True))
                                  if val is not None:
                                      print(f"    ✓ {currency_code} [actual-table]: {val} ({d})")
                                      return val, d
              except Exception as e:
                  print(f"    ✗ {country_slug}: {e}")
              return None, None

          def parse_tb(cols):
              if len(cols) < 5: return None
              val  = clean_num(cols[1].get_text(strip=True))
              unit = cols[4].get_text(strip=True)
              if val is None: return None
              scale = 1000 if 'billion' in unit.lower() else 1
              curr  = next((c for c in CURRENCIES if c in unit.upper()), 'USD')
              val_m = val * scale
              if curr != 'USD':
                  fx = exchange_rates.get(curr, 1)
                  val_m = val_m / fx if fx else val_m
              return round(val_m, 2)

          def scrape_te_list(url, indicator):
              print(f"\n{'='*50}\nSCRAPING: {indicator.upper()}\n{'='*50}")
              try:
                  r = te_get(url)
                  soup = BeautifulSoup(r.content, 'lxml')
                  data, dates = {}, {}
                  table = soup.find('table', {'class': 'table'})
                  if not table: return data, dates
                  headers = [h.get_text(strip=True).lower() for h in table.find_all('th')]
                  ai = 1
                  if 'actual' in headers: ai = headers.index('actual')
                  elif 'last' in headers: ai = headers.index('last')
                  di = headers.index('reference') if 'reference' in headers else None
                  for row in table.find_all('tr')[1:]:
                      cols = row.find_all('td')
                      if len(cols) < 2: continue
                      ctry = cols[0].get_text(strip=True)
                      for code, names in COUNTRY_NAMES.items():
                          if any(n.lower() in ctry.lower() for n in names):
                              val = parse_tb(cols) if indicator == 'tradeBalance' \
                                    else clean_num(cols[ai].get_text(strip=True))
                              d = str(date.today())
                              if di and len(cols) > di:
                                  d = parse_te_date(cols[di].get_text(strip=True))
                              if val is not None:
                                  if indicator == 'termsOfTrade' and not (TOT_MIN <= val <= TOT_MAX):
                                      print(f"  ✗ {code}: {val} (out of range)")
                                      break
                                  data[code]  = round(val, 2)
                                  dates[code] = d
                                  print(f"  ✓ {code}: {val} ({d})")
                              break
                  return data, dates
              except Exception as e:
                  print(f"  ✗ Error: {e}")
                  return {}, {}

          def scrape_fallback(indicator, url):
              if indicator == 'termsOfTrade':
                  print(f"\n{'='*50}\nSCRAPING: TERMSOFTRADE\n{'='*50}")
                  te_data, te_dates = scrape_te_list(url, indicator)
                  return fetch_all_tot(te_data, te_dates)

              data, dates = scrape_te_list(url, indicator)
              missing = [c for c in CURRENCIES if c not in data]
              if missing and indicator in INDICATOR_PAGES:
                  print(f"\n  → Country page fallback for: {', '.join(missing)}")
                  for code in missing:
                      slug = COUNTRY_URLS.get(code)
                      if slug:
                          val, d = scrape_country_page(slug, INDICATOR_PAGES[indicator], code)
                          if val is not None:
                              data[code]  = val
                              dates[code] = d or str(date.today())
                      time.sleep(1)
              return data, dates

          def load_cot():
              import os
              cot = {}
              if not os.path.exists('cot-data'): return {}
              for c in ['EUR','GBP','JPY','CAD','AUD','CHF','NZD']:
                  fp = f'cot-data/{c}.json'
                  if os.path.exists(fp):
                      try:
                          with open(fp) as f:
                              cot[c] = json.load(f).get('netPosition')
                      except: pass
              return cot

          # ═══════════════════════════════════════════════════════════════════
          # MAIN
          # ═══════════════════════════════════════════════════════════════════
          print("="*60)
          print("ECONOMIC DATA SCRAPER v8")
          print("ToT EUR: ECB TRD → Eurostat ext_lt_intercc → IMF → World Bank")
          print("ToT GBP: ONS CTSL → World Bank")
          print("="*60)

          fetch_fx()
          all_data  = {c: {} for c in CURRENCIES}
          all_dates = {c: {} for c in CURRENCIES}

          for ind, url in TRADING_ECONOMICS_URLS.items():
              ind_data, ind_dates = scrape_fallback(ind, url)
              for code, val in ind_data.items():
                  all_data[code][ind]  = val
                  all_dates[code][ind] = ind_dates.get(code, str(date.today()))
              time.sleep(2)

          for code, val in load_cot().items():
              all_data[code]['cotPositioning'] = val

          today = str(date.today())
          print("\n" + "="*60 + "\nSUMMARY\n" + "="*60)
          for curr in CURRENCIES:
              pkg = {
                  'lastUpdate': today,
                  'source': 'TradingEconomics + ONS (GBP) + ECB TRD / Eurostat / IMF (EUR) + WorldBank + COT',
                  'data':   all_data[curr],
                  'dates':  all_dates[curr],
              }
              with open(f'economic-data/{curr}.json', 'w') as f:
                  json.dump(pkg, f, indent=2)
              missing = [k for k in ['retailSales','wageGrowth','manufacturingPMI','termsOfTrade']
                         if all_data[curr].get(k) is None]
              tot    = all_data[curr].get('termsOfTrade')
              status = '✓' if not missing else '⚠'
              print(f"  {status} {curr}: ToT={tot}{' | Missing: '+', '.join(missing) if missing else ''}")

          print("\nCOMPLETED")
          EOFPYTHON

      - name: Commit and push
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add economic-data/
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Economic data $(date +'%Y-%m-%d') - ToT v8"
            git pull --rebase origin main || true
            git push
          fi
