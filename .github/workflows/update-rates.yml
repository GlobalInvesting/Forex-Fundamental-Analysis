name: Update Interest Rates (100% Web Scraping + Dates)
on:
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch:

jobs:
  update-rates:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 lxml --break-system-packages
      
      - name: Create rates directory
        run: mkdir -p rates
      
      - name: Fetch all rates via web scraping
        run: |
          cat > fetch_rates.py << 'EOFPYTHON'
          import requests
          from bs4 import BeautifulSoup
          import json
          import re
          from datetime import date, datetime
          import time
          import os
          
          HEADERS = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
          }
          
          def clean_rate(text):
              if not text:
                  return None
              text = str(text).strip().replace('%', '').replace(',', '.')
              match = re.search(r'(-?\d+\.?\d*)', text)
              if match:
                  try:
                      val = float(match.group(1))
                      if -5 <= val <= 25:
                          return match.group(1)
                  except:
                      pass
              return None

          def load_existing_observations(currency):
              path = f'rates/{currency}.json'
              if not os.path.exists(path):
                  return []
              try:
                  with open(path) as f:
                      data = json.load(f)
                  return data.get('observations', [])
              except Exception as e:
                  print(f"    Warning: could not read existing history for {currency}: {e}")
                  return []

          def merge_observations(existing, new_obs):
              """
              Merges new observation with existing history.
              - Deduplicates by date (new value overwrites if same date).
              - Keeps sorted most-recent first.
              - Caps at 36 months.
              """
              obs_map = {o['date']: o for o in existing}
              obs_map[new_obs['date']] = new_obs
              sorted_obs = sorted(obs_map.values(), key=lambda x: x['date'], reverse=True)
              return sorted_obs[:36]
          
          def fetch_trading_economics():
              print("\n" + "="*70)
              print("SOURCE: Trading Economics (Interest Rates)")
              print("="*70)
              
              try:
                  url = "https://tradingeconomics.com/country-list/interest-rate?continent=world"
                  r = requests.get(url, headers=HEADERS, timeout=15)
                  if r.status_code == 429:
                      print("  Rate limited, waiting 30s...")
                      time.sleep(30)
                      r = requests.get(url, headers=HEADERS, timeout=15)
                  r.raise_for_status()
                  soup = BeautifulSoup(r.content, 'lxml')
                  
                  rates = {}
                  country_map = {
                      'United States': 'USD',
                      'Euro Area': 'EUR',
                      'United Kingdom': 'GBP',
                      'Japan': 'JPY',
                      'Canada': 'CAD',
                      'Australia': 'AUD',
                      'Switzerland': 'CHF',
                      'New Zealand': 'NZD'
                  }
                  
                  table = soup.find('table', {'class': 'table'})
                  if not table:
                      print("  ERROR: No table found")
                      return rates
                  
                  headers_row = table.find('thead')
                  header_texts = []
                  if headers_row:
                      header_texts = [th.get_text(strip=True).lower()
                                      for th in headers_row.find_all('th')]
                  
                  last_idx = 1
                  if header_texts:
                      if 'last' in header_texts:
                          last_idx = header_texts.index('last')
                      elif 'actual' in header_texts:
                          last_idx = header_texts.index('actual')
                  
                  for row in table.find_all('tr')[1:]:
                      cols = row.find_all('td')
                      if len(cols) < 2:
                          continue
                      
                      country = cols[0].get_text(strip=True)
                      
                      for country_name, currency in country_map.items():
                          if country_name.lower() in country.lower():
                              rate_text = cols[last_idx].get_text(strip=True) if last_idx < len(cols) else ''
                              rate = clean_rate(rate_text)
                              
                              if rate is not None:
                                  rates[currency] = rate
                                  print(f"  OK {currency}: {rate}%")
                              break
                  
                  return rates
                  
              except Exception as e:
                  print(f"  ERROR: {e}")
                  return {}

          def fetch_global_rates_fallback(currency):
              urls = {
                  'USD': 'central-bank-america/fed-interest-rate.aspx',
                  'EUR': 'central-bank-europe/ecb-interest-rate.aspx',
                  'GBP': 'central-bank-england/boe-interest-rate.aspx',
                  'JPY': 'central-bank-japan/boj-interest-rate.aspx',
                  'CHF': 'central-bank-switzerland/snb-interest-rate.aspx',
                  'CAD': 'central-bank-canada/boc-interest-rate.aspx',
                  'AUD': 'central-bank-australia/rba-interest-rate.aspx',
                  'NZD': 'central-bank-new-zealand/rbnz-interest-rate.aspx'
              }
              if currency not in urls:
                  return None
              try:
                  url = f"https://www.global-rates.com/en/interest-rates/central-banks/{urls[currency]}"
                  r = requests.get(url, headers=HEADERS, timeout=10)
                  soup = BeautifulSoup(r.content, 'lxml')
                  for table in soup.find_all('table'):
                      rows = table.find_all('tr')
                      if len(rows) >= 2:
                          cols = rows[1].find_all('td')
                          if len(cols) >= 2:
                              rate = clean_rate(cols[1].get_text(strip=True))
                              if rate:
                                  print(f"  OK {currency}: {rate}% (fallback global-rates.com)")
                                  return rate
              except Exception as e:
                  print(f"    Fallback error for {currency}: {e}")
              return None

          # ============================================
          # MAIN
          # ============================================

          today = str(date.today())
          currencies_needed = ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD']

          print(f"\nDate: {today}")

          final_rates = fetch_trading_economics()
          time.sleep(1)

          missing = [c for c in currencies_needed if c not in final_rates]
          if missing:
              print(f"\nFallback for: {', '.join(missing)}")
              for currency in missing:
                  rate = fetch_global_rates_fallback(currency)
                  if rate:
                      final_rates[currency] = rate
                  time.sleep(0.5)

          # ============================================
          # SAVE â€” always use today as the observation date
          # This guarantees the scraped value is always observations[0]
          # regardless of what reference period TE shows.
          # ============================================

          print("\n" + "="*70)
          print("SAVING WITH HISTORICAL ACCUMULATION")
          print("="*70)

          for currency in currencies_needed:
              if currency not in final_rates:
                  print(f"  SKIP {currency}: no data obtained")
                  continue

              existing_obs = load_existing_observations(currency)

              # KEY FIX: date = today, not TE's reference period
              # This ensures observations[0] is always the latest scraped value
              new_observation = {
                  'value': final_rates[currency],
                  'date': today,
                  'source': 'TradingEconomics'
              }

              merged_obs = merge_observations(existing_obs, new_observation)

              rate_data = {
                  'observations': merged_obs,
                  'lastUpdate': today,
                  'totalObservations': len(merged_obs)
              }

              with open(f'rates/{currency}.json', 'w') as f:
                  json.dump(rate_data, f, indent=2)

              print(f"  SAVED {currency}: {final_rates[currency]}% | history: {len(merged_obs)} obs")

          missing_final = [c for c in currencies_needed if c not in final_rates]
          if missing_final:
              print(f"\nMISSING: {', '.join(missing_final)}")
              exit(1)
          else:
              print(f"\nALL CURRENCIES UPDATED OK")

          EOFPYTHON
          
          python fetch_rates.py
      
      - name: Display summary
        run: |
          echo ""
          echo "========================================"
          echo "         INTEREST RATES SUMMARY"
          echo "========================================"
          echo ""
          for currency in USD EUR GBP JPY CAD AUD CHF NZD; do
            if [ -f "rates/$currency.json" ]; then
              echo "[$currency]"
              python3 -c "
          import json
          with open('rates/$currency.json') as f:
              data = json.load(f)
          obs = data['observations']
          print(f'  Rate:     {obs[0][\"value\"]}%')
          print(f'  Date:     {obs[0][\"date\"]}')
          print(f'  History:  {len(obs)} observations')
          print(f'  Oldest:   {obs[-1][\"date\"]} = {obs[-1][\"value\"]}%')
          "
              echo ""
            fi
          done
      
      - name: Commit and push
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add rates/
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "Rates $(date +'%Y-%m-%d') - TradingEconomics scraping"
            git pull --rebase origin main || true
            git push
          fi
